{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns=None\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>145500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>370000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>103.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>127000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>81.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>67.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  selling_price  km_driven  fuel  transmission  owner  engine  \\\n",
       "0  2014.0       450000.0   145500.0     1             2      0  1248.0   \n",
       "1  2014.0       370000.0   120000.0     1             2      1  1498.0   \n",
       "2  2010.0       225000.0   127000.0     1             2      0  1396.0   \n",
       "3  2017.0       440000.0    45000.0     2             2      0  1197.0   \n",
       "4  2011.0       350000.0    90000.0     1             2      0  1364.0   \n",
       "\n",
       "   max_power  \n",
       "0      74.00  \n",
       "1     103.52  \n",
       "2      90.00  \n",
       "3      81.86  \n",
       "4      67.10  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data_csv/data_cleaned.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## full_suite for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package deepchecks:\n",
      "\n",
      "NAME\n",
      "    deepchecks - Top module for deepchecks library.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    base (package)\n",
      "    checks (package)\n",
      "    datasets (package)\n",
      "    errors\n",
      "    ppscore\n",
      "    suites (package)\n",
      "    utils (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        deepchecks.base.check.BaseCheck\n",
      "            deepchecks.base.check.ModelComparisonBaseCheck\n",
      "            deepchecks.base.check.ModelOnlyBaseCheck\n",
      "            deepchecks.base.check.SingleDatasetBaseCheck\n",
      "            deepchecks.base.check.TrainTestBaseCheck\n",
      "        deepchecks.base.check.CheckFailure\n",
      "        deepchecks.base.check.CheckResult\n",
      "        deepchecks.base.condition.Condition\n",
      "        deepchecks.base.condition.ConditionResult\n",
      "        deepchecks.base.dataset.Dataset\n",
      "        deepchecks.base.suite.BaseSuite\n",
      "            deepchecks.base.suite.ModelComparisonSuite\n",
      "            deepchecks.base.suite.Suite\n",
      "        deepchecks.base.suite.SuiteResult\n",
      "    enum.Enum(builtins.object)\n",
      "        deepchecks.base.condition.ConditionCategory\n",
      "    \n",
      "    class BaseCheck(builtins.object)\n",
      "     |  Base class for check.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, tabs=0, prefix='')\n",
      "     |      Representation of check as string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tabs (int): number of tabs to shift by the output\n",
      "     |  \n",
      "     |  add_condition(self, name: str, condition_func: Callable[[Any], Union[deepchecks.base.condition.ConditionResult, bool]], **params)\n",
      "     |      Add new condition function to the check.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          name (str): Name of the condition. should explain the condition action and parameters\n",
      "     |          condition_func (Callable[[Any], Union[List[ConditionResult], bool]]): Function which gets the value of the\n",
      "     |              check and returns object of List[ConditionResult] or boolean.\n",
      "     |          params: Additional parameters to pass when calling the condition function.\n",
      "     |  \n",
      "     |  clean_conditions(self)\n",
      "     |      Remove all conditions from this check instance.\n",
      "     |  \n",
      "     |  conditions_decision(self, result: deepchecks.base.check.CheckResult) -> List[deepchecks.base.condition.ConditionResult]\n",
      "     |      Run conditions on given result.\n",
      "     |  \n",
      "     |  params(self) -> Dict\n",
      "     |      Return parameters to show when printing the check.\n",
      "     |  \n",
      "     |  remove_condition(self, index: int)\n",
      "     |      Remove given condition by index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index (int): index of condtion to remove\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  name() from abc.ABCMeta\n",
      "     |      Name of class in split camel case.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_conditions': <class 'collections.OrderedDict'>, '...\n",
      "    \n",
      "    class BaseSuite(builtins.object)\n",
      "     |  BaseSuite(name: str, *checks)\n",
      "     |  \n",
      "     |  Class for running a set of checks together, and returning a unified pass / no-pass.\n",
      "     |  \n",
      "     |  Attributes:\n",
      "     |      checks: A list of checks to run.\n",
      "     |      name: Name of the suite\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      Access check inside the suite by name.\n",
      "     |  \n",
      "     |  __init__(self, name: str, *checks)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, tabs=0)\n",
      "     |      Representation of suite as string.\n",
      "     |  \n",
      "     |  add(self, check)\n",
      "     |      Add a check or a suite to current suite.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          check (BaseCheck): A check or suite to add.\n",
      "     |  \n",
      "     |  remove(self, index: int)\n",
      "     |      Remove a check by given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index (int): Index of check to remove.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  supported_checks() -> Tuple from builtins.type\n",
      "     |      Return list of of supported check types.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'_check_index': <class 'int'>, 'checks': <class 'co...\n",
      "    \n",
      "    class CheckFailure(builtins.object)\n",
      "     |  CheckFailure(check: deepchecks.base.check.BaseCheck, exception: Exception, header_suffix: str = '')\n",
      "     |  \n",
      "     |  Class which holds a run exception of a check.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, check: deepchecks.base.check.BaseCheck, exception: Exception, header_suffix: str = '')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return string representation.\n",
      "     |  \n",
      "     |  to_json(self, with_display: bool = True)\n",
      "     |      Return check failure as json.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          with_display (bool): controls if to serialize display or not\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          {'name': .., 'params': .., 'header': .., 'display': ..}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class CheckResult(builtins.object)\n",
      "     |  CheckResult(value, header: str = None, display: Any = None)\n",
      "     |  \n",
      "     |  Class which returns from a check with result that can later be used for automatic pipelines and display value.\n",
      "     |  \n",
      "     |  Class containing the result of a check\n",
      "     |  \n",
      "     |  The class stores the results and display of the check. Evaluating the result in an IPython console / notebook\n",
      "     |  will show the result display output.\n",
      "     |  \n",
      "     |  Attributes:\n",
      "     |      value (Any): Value calculated by check. Can be used to decide if decidable check passed.\n",
      "     |      display (Dict): Dictionary with formatters for display. possible formatters are: 'text/html', 'image/png'\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, value, header: str = None, display: Any = None)\n",
      "     |      Init check result.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          value (Any): Value calculated by check. Can be used to decide if decidable check passed.\n",
      "     |          header (str): Header to be displayed in python notebook.\n",
      "     |          check (Class): The check class which created this result. Used to extract the summary to be\n",
      "     |              displayed in notebook.\n",
      "     |          display (List): Objects to be displayed (dataframe or function or html)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return default __repr__ function uses value.\n",
      "     |  \n",
      "     |  display_check(self, unique_id: str = None, as_widget: bool = False, show_additional_outputs=True)\n",
      "     |      Display the check result or return the display as widget.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          unique_id (str):\n",
      "     |              The unique id given by the suite that displays the check.\n",
      "     |          as_widget (bool):\n",
      "     |              Boolean that controls if to display the check regulary or if to return a widget.\n",
      "     |          show_additional_outputs (bool):\n",
      "     |              Boolean that controls if to show additional outputs.\n",
      "     |      Returns:\n",
      "     |          Widget representation of the display if as_widget is True.\n",
      "     |  \n",
      "     |  get_header(self)\n",
      "     |      Return header for display. if header was defined return it, else extract name of check class.\n",
      "     |  \n",
      "     |  have_conditions(self) -> bool\n",
      "     |      Return if this check have condition results.\n",
      "     |  \n",
      "     |  have_display(self) -> bool\n",
      "     |      Return if this check have dsiplay.\n",
      "     |  \n",
      "     |  passed_conditions(self)\n",
      "     |      Return if this check have not passing condition results.\n",
      "     |  \n",
      "     |  process_conditions(self)\n",
      "     |      Process the conditions results from current result and check.\n",
      "     |  \n",
      "     |  show(self, unique_id=None, show_additional_outputs=True)\n",
      "     |      Display check result.\n",
      "     |  \n",
      "     |  to_json(self, with_display: bool = True)\n",
      "     |      Return check result as json.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          with_display (bool): controls if to serialize display or not\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          json in the format:\n",
      "     |          {'name': .., 'params': .., 'header': ..,\n",
      "     |           'summary': .., 'conditions_table': .., 'value', 'display': ..}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  display_from_json(json_data)\n",
      "     |      Display the check result from a json received from a to_json.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  priority\n",
      "     |      Return priority of the current result.\n",
      "     |      \n",
      "     |      This value is primarly used to determine suite output order.\n",
      "     |      The logic is next:\n",
      "     |          - if at least one condition did not pass and is of category 'FAIL', return 1;\n",
      "     |          - if at least one condition did not pass and is of category 'WARN', return 2;\n",
      "     |          - if check result do not have assigned conditions, return 3\n",
      "     |          - if all conditions passed, return 4;\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          int: priority of the cehck result.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'check': 'BaseCheck', 'conditions_results': typing....\n",
      "    \n",
      "    class Condition(builtins.object)\n",
      "     |  Condition(name: str, function: Callable, params: Dict)\n",
      "     |  \n",
      "     |  Contain condition attributes.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, *args, **kwargs) -> 'ConditionResult'\n",
      "     |      Run this condition.\n",
      "     |  \n",
      "     |  __init__(self, name: str, function: Callable, params: Dict)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'function': typing.Callable, 'name': <class 'str'>,...\n",
      "    \n",
      "    class ConditionCategory(enum.Enum)\n",
      "     |  ConditionCategory(value, names=None, *, module=None, qualname=None, type=None, start=1)\n",
      "     |  \n",
      "     |  Condition result category. indicates whether the result should fail the suite.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConditionCategory\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  FAIL = <ConditionCategory.FAIL: 'FAIL'>\n",
      "     |  \n",
      "     |  WARN = <ConditionCategory.WARN: 'WARN'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from enum.EnumMeta:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class ConditionResult(builtins.object)\n",
      "     |  ConditionResult(is_pass: bool, details: str = '', category: deepchecks.base.condition.ConditionCategory = <ConditionCategory.FAIL: 'FAIL'>)\n",
      "     |  \n",
      "     |  Contain result of a condition function.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, is_pass: bool, details: str = '', category: deepchecks.base.condition.ConditionCategory = <ConditionCategory.FAIL: 'FAIL'>)\n",
      "     |      Initialize condition result.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          is_pass (bool): Whether the condition functions passed the given value or not.\n",
      "     |          details (str): What actually happened in the condition.\n",
      "     |          category (ConditionCategory): The category to which the condition result belongs.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return string representation for printing.\n",
      "     |  \n",
      "     |  get_icon(self)\n",
      "     |      Return icon of the result to display.\n",
      "     |  \n",
      "     |  set_name(self, name: str)\n",
      "     |      Set name to be displayed in table.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          name (str): Description of the condition to be displayed.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  priority\n",
      "     |      Return priority of the current condition.\n",
      "     |      \n",
      "     |      This value is primarily used to determine the order in which\n",
      "     |      conditions should be displayed.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          int: condition priority value;\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'category': <enum 'ConditionCategory'>, 'details': ...\n",
      "    \n",
      "    class Dataset(builtins.object)\n",
      "     |  Dataset(df: pandas.core.frame.DataFrame, label: Union[deepchecks.utils.typing.Hashable, pandas.core.series.Series, pandas.core.frame.DataFrame, numpy.ndarray] = None, features: Optional[Sequence[deepchecks.utils.typing.Hashable]] = None, cat_features: Optional[Sequence[deepchecks.utils.typing.Hashable]] = None, index_name: Optional[deepchecks.utils.typing.Hashable] = None, set_index_from_dataframe_index: bool = False, datetime_name: Optional[deepchecks.utils.typing.Hashable] = None, set_datetime_from_dataframe_index: bool = False, convert_datetime: bool = True, datetime_args: Optional[Dict] = None, max_categorical_ratio: float = 0.01, max_categories: int = 30, max_float_categories: int = 5, label_type: str = None)\n",
      "     |  \n",
      "     |  Dataset wraps pandas DataFrame together with ML related metadata.\n",
      "     |  \n",
      "     |  The Dataset class is containing additional data and methods intended for easily accessing\n",
      "     |  metadata relevant for the training or validating of an ML models.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |      df (pandas.DataFrame):\n",
      "     |          A pandas DataFrame containing data relevant for the training or validating of a ML models.\n",
      "     |      label (t.Union[Hashable, pd.Series, pd.DataFrame, np.ndarray])\n",
      "     |          label column provided either as a string with the name of an existing column in the DataFrame or a label\n",
      "     |          object including the label data (pandas Series/DataFrame or a numpy array) that will be concatenated to the\n",
      "     |          data in the DataFrame. in case of label data the following logic is applied to set the label name:\n",
      "     |              - Series: takes the series name or 'target' if name is empty\n",
      "     |              - DataFrame: expect single column in the dataframe and use its name\n",
      "     |              - numpy: use 'target'\n",
      "     |      features (Optional[Sequence[Hashable]]):\n",
      "     |          List of names for the feature columns in the DataFrame.\n",
      "     |      cat_features (Optional[Sequence[Hashable]]):\n",
      "     |          List of names for the categorical features in the DataFrame. In order to disable categorical.\n",
      "     |          features inference, pass cat_features=[]\n",
      "     |      index_name (Optional[Hashable]):\n",
      "     |          Name of the index column in the dataframe. If set_index_from_dataframe_index is True and index_name\n",
      "     |          is not None, index will be created from the dataframe index level with the given name. If index levels\n",
      "     |          have no names, an int must be used to select the appropriate level by order.\n",
      "     |      set_index_from_dataframe_index (bool, default False):\n",
      "     |          If set to true, index will be created from the dataframe index instead of dataframe columns (default).\n",
      "     |          If index_name is None, first level of the index will be used in case of a multilevel index.\n",
      "     |      datetime_name (Optional[Hashable]):\n",
      "     |          Name of the datetime column in the dataframe. If set_datetime_from_dataframe_index is True and datetime_name\n",
      "     |          is not None, date will be created from the dataframe index level with the given name. If index levels\n",
      "     |          have no names, an int must be used to select the appropriate level by order.\n",
      "     |      set_datetime_from_dataframe_index (bool, default False):\n",
      "     |          If set to true, date will be created from the dataframe index instead of dataframe columns (default).\n",
      "     |          If datetime_name is None, first level of the index will be used in case of a multilevel index.\n",
      "     |      convert_datetime (bool, default True):\n",
      "     |          If set to true, date will be converted to datetime using pandas.to_datetime.\n",
      "     |      datetime_args (Optional[Dict]):\n",
      "     |          pandas.to_datetime args used for conversion of the datetime column.\n",
      "     |          (look at https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html for more documentation)\n",
      "     |      max_categorical_ratio (float, default 0.01):\n",
      "     |          The max ratio of unique values in a column in order for it to be inferred as a\n",
      "     |          categorical feature.\n",
      "     |      max_categories (int, default 30):\n",
      "     |          The maximum number of categories in a column in order for it to be inferred as a categorical\n",
      "     |          feature.\n",
      "     |      max_float_categories (int, default 5):\n",
      "     |          The maximum number of categories in a float column in order for it to be inferred as a\n",
      "     |          categorical feature.\n",
      "     |      label_type (str, default None):\n",
      "     |          Used to assume target model type if not found on model. Values ('classification_label', 'regression_label')\n",
      "     |          If None then label type is inferred from label using is_categorical logic.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, df: pandas.core.frame.DataFrame, label: Union[deepchecks.utils.typing.Hashable, pandas.core.series.Series, pandas.core.frame.DataFrame, numpy.ndarray] = None, features: Optional[Sequence[deepchecks.utils.typing.Hashable]] = None, cat_features: Optional[Sequence[deepchecks.utils.typing.Hashable]] = None, index_name: Optional[deepchecks.utils.typing.Hashable] = None, set_index_from_dataframe_index: bool = False, datetime_name: Optional[deepchecks.utils.typing.Hashable] = None, set_datetime_from_dataframe_index: bool = False, convert_datetime: bool = True, datetime_args: Optional[Dict] = None, max_categorical_ratio: float = 0.01, max_categories: int = 30, max_float_categories: int = 5, label_type: str = None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self) -> int\n",
      "     |      Return number of samples in the member dataframe.\n",
      "     |  \n",
      "     |  copy(self: ~TDataset, new_data: pandas.core.frame.DataFrame) -> ~TDataset\n",
      "     |      Create a copy of this Dataset with new data.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          new_data (DataFrame): new data from which new dataset will be created\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Dataset: new dataset instance\n",
      "     |  \n",
      "     |  get_datetime_column_from_index(self, datetime_name)\n",
      "     |      Retrieve the datetime info from the index if _set_datetime_from_dataframe_index is True.\n",
      "     |  \n",
      "     |  is_categorical(self, col_name: deepchecks.utils.typing.Hashable) -> bool\n",
      "     |      Check if uniques are few enough to count as categorical.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          col_name (str): The name of the column in the dataframe\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          If is categorical according to input numbers\n",
      "     |  \n",
      "     |  sample(self: ~TDataset, n_samples: int, replace: bool = False, random_state: Optional[int] = None, drop_na_label: bool = False) -> ~TDataset\n",
      "     |      Create a copy of the dataset object, with the internal dataframe being a sample of the original dataframe.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          n_samples (int): Number of samples to draw.\n",
      "     |          replace (bool, default False): Whether to sample with replacement.\n",
      "     |          random_state (int, default None): Random state.\n",
      "     |          drop_na_label (bool, default False): Whether to take sample only from rows with exiting label.\n",
      "     |      Returns:\n",
      "     |          Dataset: instance of the Dataset with sampled internal dataframe.\n",
      "     |  \n",
      "     |  select(self: ~TDataset, columns: Union[deepchecks.utils.typing.Hashable, List[deepchecks.utils.typing.Hashable], NoneType] = None, ignore_columns: Union[deepchecks.utils.typing.Hashable, List[deepchecks.utils.typing.Hashable], NoneType] = None) -> ~TDataset\n",
      "     |      Filter dataset columns by given params.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          columns (Union[Hashable, List[Hashable], None]): Column names to keep.\n",
      "     |          ignore_columns (Union[Hashable, List[Hashable], None]): Column names to drop.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          TDataset: horizontally filtered dataset\n",
      "     |      \n",
      "     |      Raise:\n",
      "     |          DeepchecksValueError: In case one of columns given don't exists raise error\n",
      "     |  \n",
      "     |  train_test_split(self: ~TDataset, train_size: Union[int, float, NoneType] = None, test_size: Union[int, float] = 0.25, random_state: int = 42, shuffle: bool = True, stratify: Union[List, pandas.core.series.Series, numpy.ndarray, bool] = False) -> Tuple[~TDataset, ~TDataset]\n",
      "     |      Split dataset into random train and test datasets.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          train_size (float or int):\n",
      "     |              If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in\n",
      "     |              the train split. If int, represents the absolute number of train samples. If None, the value is\n",
      "     |              automatically set to the complement of the test size.(default = None)\n",
      "     |          test_size (float or int):\n",
      "     |              If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the\n",
      "     |              test split. If int, represents the absolute number of test samples. (default = 0.25)\n",
      "     |          random_state (int):\n",
      "     |              The random state to use for shuffling. (default=42)\n",
      "     |          shuffle (bool):\n",
      "     |              Whether or not to shuffle the data before splitting. (default=True)\n",
      "     |          stratify (List, pd.Series, np.ndarray, bool):\n",
      "     |              If True, data is split in a stratified fashion, using the class labels. If array-like, data is split in\n",
      "     |              a stratified fashion, using this as class labels. (default=False)\n",
      "     |      Returns:\n",
      "     |          (Dataset) Dataset containing train split data.\n",
      "     |          (Dataset) Dataset containing test split data.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  datasets_share_categorical_features(datasets: List[ForwardRef('Dataset')]) -> bool from builtins.type\n",
      "     |      Verify that all provided datasets share same categorical features.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          datasets (List[Dataset]): list of datasets to validate\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          bool: True if all datasets share same categorical features, otherwise False\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AssertionError:\n",
      "     |              'datasets' parameter is not a list;\n",
      "     |              'datasets' contains less than one dataset;\n",
      "     |  \n",
      "     |  datasets_share_features(datasets: List[ForwardRef('Dataset')]) -> bool from builtins.type\n",
      "     |      Verify that all provided datasets share same features.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          datasets (List[Dataset]): list of datasets to validate\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          bool: True if all datasets share same features, otherwise False\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AssertionError:\n",
      "     |              'datasets' parameter is not a list;\n",
      "     |              'datasets' contains less than one dataset;\n",
      "     |  \n",
      "     |  datasets_share_label(datasets: List[ForwardRef('Dataset')]) -> bool from builtins.type\n",
      "     |      Verify that all provided datasets share same label column.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          datasets (List[Dataset]): list of datasets to validate\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          bool: True if all datasets share same categorical features, otherwise False\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          AssertionError:\n",
      "     |              'datasets' parameter is not a list;\n",
      "     |              'datasets' contains less than one dataset;\n",
      "     |  \n",
      "     |  ensure_not_empty_dataset(obj: Any, *, cast: bool = False) -> 'Dataset' from builtins.type\n",
      "     |      Verify Dataset or transform to Dataset.\n",
      "     |      \n",
      "     |      Function verifies that provided value is a non-empty instance of Dataset,\n",
      "     |      otherwise raises an exception, but if the 'cast' flag is set to True it will\n",
      "     |      also try to transform provided value to the Dataset instance.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          obj (Any):\n",
      "     |              value to verify\n",
      "     |          cast (bool, default False):\n",
      "     |              to try to transform the value or not\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          DeepchecksValueError:\n",
      "     |              if the provided value is not a Dataset instance;\n",
      "     |              if the provided value cannot be transformed into Dataset instance;\n",
      "     |          DatasetValidationError:\n",
      "     |              if the provided value is empty Dataset instance;\n",
      "     |  \n",
      "     |  from_numpy(*args: numpy.ndarray, columns: Sequence[deepchecks.utils.typing.Hashable] = None, label_name: Hashable = None, **kwargs) -> ~TDataset from builtins.type\n",
      "     |      Create Dataset instance from numpy arrays.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: (np.ndarray):\n",
      "     |              Numpy array of data columns, and second optional numpy array of labels.\n",
      "     |          columns (Sequence[Hashable], default None):\n",
      "     |              names for the columns. If none provided, the names that will be automatically\n",
      "     |              assigned to the columns will be: 1 - n (where n - number of columns)\n",
      "     |          label_name (Hashable, default None):\n",
      "     |              labels column name. If none is provided, the name 'target' will be used.\n",
      "     |          **kwargs:\n",
      "     |              additional arguments that will be passed to the main Dataset constructor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Dataset: instance of the Dataset\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          DeepchecksValueError:\n",
      "     |              if receives zero or more than two numpy arrays;\n",
      "     |              if columns (args[0]) is not two dimensional numpy array;\n",
      "     |              if labels (args[1]) is not one dimensional numpy array;\n",
      "     |              if features array or labels array is empty;\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import numpy\n",
      "     |      >>> from deepchecks import Dataset\n",
      "     |      \n",
      "     |      >>> features = numpy.array([[0.25, 0.3, 0.3],\n",
      "     |      ...                        [0.14, 0.75, 0.3],\n",
      "     |      ...                        [0.23, 0.39, 0.1]])\n",
      "     |      >>> labels = numpy.array([0.1, 0.1, 0.7])\n",
      "     |      >>> dataset = Dataset.from_numpy(features, labels)\n",
      "     |      \n",
      "     |      Creating dataset only from features array.\n",
      "     |      \n",
      "     |      >>> dataset = Dataset.from_numpy(features)\n",
      "     |      \n",
      "     |      Passing additional arguments to the main Dataset constructor\n",
      "     |      \n",
      "     |      >>> dataset = Dataset.from_numpy(features, labels, max_categorical_ratio=0.5)\n",
      "     |      \n",
      "     |      Specifying features and label columns names.\n",
      "     |      \n",
      "     |      >>> dataset = Dataset.from_numpy(\n",
      "     |      ...     features, labels,\n",
      "     |      ...     columns=['sensor-1', 'sensor-2', 'sensor-3'],\n",
      "     |      ...     label_name='labels'\n",
      "     |      ... )\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  cat_features\n",
      "     |      Return list of categorical feature names.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         List of categorical feature names.\n",
      "     |  \n",
      "     |  classes\n",
      "     |      Return the classes from label column in sorted list. if no label column defined, return empty list.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Sorted classes\n",
      "     |  \n",
      "     |  columns_info\n",
      "     |      Return the role and logical type of each column.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         Directory of a column and its role\n",
      "     |  \n",
      "     |  data\n",
      "     |      Return the data of dataset.\n",
      "     |  \n",
      "     |  datetime_col\n",
      "     |      Return datetime column if exists.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         (Series): Series of the datetime column\n",
      "     |  \n",
      "     |  datetime_name\n",
      "     |      If datetime column exists, return its name.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         (str) datetime name\n",
      "     |  \n",
      "     |  features\n",
      "     |      Return list of feature names.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         List of feature names.\n",
      "     |  \n",
      "     |  features_columns\n",
      "     |      Return features columns if exists.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         Features columns\n",
      "     |  \n",
      "     |  index_col\n",
      "     |      Return index column. Index can be a named column or DataFrame index.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         If index column exists, returns a pandas Series of the index column.\n",
      "     |  \n",
      "     |  index_name\n",
      "     |      If index column exists, return its name.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         (str) index name\n",
      "     |  \n",
      "     |  label_col\n",
      "     |      Return label column if exists.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         Label column\n",
      "     |  \n",
      "     |  label_name\n",
      "     |      If label column exists, return its name.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         (str) Label name\n",
      "     |  \n",
      "     |  label_type\n",
      "     |      Return the label type.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Label type\n",
      "     |  \n",
      "     |  n_samples\n",
      "     |      Return number of samples in dataframe.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         Number of samples in dataframe\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'_cat_features': typing.List[deepchecks.utils.typin...\n",
      "    \n",
      "    class ModelComparisonBaseCheck(BaseCheck)\n",
      "     |  Parent class for check that compares between two or more models.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ModelComparisonBaseCheck\n",
      "     |      BaseCheck\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  run(self, train_datasets: Union[deepchecks.base.dataset.Dataset, List[deepchecks.base.dataset.Dataset]], test_datasets: Union[deepchecks.base.dataset.Dataset, List[deepchecks.base.dataset.Dataset]], models: Union[List[Any], Mapping[str, Any]]) -> deepchecks.base.check.CheckResult\n",
      "     |      Initialize context and pass to check logic.\n",
      "     |  \n",
      "     |  run_logic(self, context: deepchecks.base.check.ModelComparisonContext) -> deepchecks.base.check.CheckResult\n",
      "     |      Implement here logic of check.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'run_logic'})\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCheck:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, tabs=0, prefix='')\n",
      "     |      Representation of check as string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tabs (int): number of tabs to shift by the output\n",
      "     |  \n",
      "     |  add_condition(self, name: str, condition_func: Callable[[Any], Union[deepchecks.base.condition.ConditionResult, bool]], **params)\n",
      "     |      Add new condition function to the check.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          name (str): Name of the condition. should explain the condition action and parameters\n",
      "     |          condition_func (Callable[[Any], Union[List[ConditionResult], bool]]): Function which gets the value of the\n",
      "     |              check and returns object of List[ConditionResult] or boolean.\n",
      "     |          params: Additional parameters to pass when calling the condition function.\n",
      "     |  \n",
      "     |  clean_conditions(self)\n",
      "     |      Remove all conditions from this check instance.\n",
      "     |  \n",
      "     |  conditions_decision(self, result: deepchecks.base.check.CheckResult) -> List[deepchecks.base.condition.ConditionResult]\n",
      "     |      Run conditions on given result.\n",
      "     |  \n",
      "     |  params(self) -> Dict\n",
      "     |      Return parameters to show when printing the check.\n",
      "     |  \n",
      "     |  remove_condition(self, index: int)\n",
      "     |      Remove given condition by index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index (int): index of condtion to remove\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from BaseCheck:\n",
      "     |  \n",
      "     |  name() from abc.ABCMeta\n",
      "     |      Name of class in split camel case.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCheck:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ModelComparisonSuite(BaseSuite)\n",
      "     |  ModelComparisonSuite(name: str, *checks)\n",
      "     |  \n",
      "     |  Suite to run checks of types: CompareModelsBaseCheck.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ModelComparisonSuite\n",
      "     |      BaseSuite\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  run(self, train_datasets: Union[deepchecks.base.dataset.Dataset, Container[deepchecks.base.dataset.Dataset]], test_datasets: Union[deepchecks.base.dataset.Dataset, Container[deepchecks.base.dataset.Dataset]], models: Union[Container[Any], Mapping[str, Any]]) -> deepchecks.base.suite.SuiteResult\n",
      "     |      Run all checks.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        train_datasets: 1 or more dataset object, representing data an estimator was fitted on\n",
      "     |        test_datasets: 1 or more dataset object, representing data an estimator was fitted on\n",
      "     |        models: 2 or more scikit-learn-compatible fitted estimator instance\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        List[CheckResult] - All results by all initialized checks\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |           ValueError if check_datasets_policy is not of allowed types\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  supported_checks() -> Tuple from builtins.type\n",
      "     |      Return tuple of supported check types of this suite.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSuite:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      Access check inside the suite by name.\n",
      "     |  \n",
      "     |  __init__(self, name: str, *checks)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, tabs=0)\n",
      "     |      Representation of suite as string.\n",
      "     |  \n",
      "     |  add(self, check)\n",
      "     |      Add a check or a suite to current suite.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          check (BaseCheck): A check or suite to add.\n",
      "     |  \n",
      "     |  remove(self, index: int)\n",
      "     |      Remove a check by given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index (int): Index of check to remove.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseSuite:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ModelOnlyBaseCheck(BaseCheck)\n",
      "     |  Parent class for checks that only use a model and no datasets.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ModelOnlyBaseCheck\n",
      "     |      BaseCheck\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  run(self, model) -> deepchecks.base.check.CheckResult\n",
      "     |      Define run signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'run'})\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCheck:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, tabs=0, prefix='')\n",
      "     |      Representation of check as string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tabs (int): number of tabs to shift by the output\n",
      "     |  \n",
      "     |  add_condition(self, name: str, condition_func: Callable[[Any], Union[deepchecks.base.condition.ConditionResult, bool]], **params)\n",
      "     |      Add new condition function to the check.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          name (str): Name of the condition. should explain the condition action and parameters\n",
      "     |          condition_func (Callable[[Any], Union[List[ConditionResult], bool]]): Function which gets the value of the\n",
      "     |              check and returns object of List[ConditionResult] or boolean.\n",
      "     |          params: Additional parameters to pass when calling the condition function.\n",
      "     |  \n",
      "     |  clean_conditions(self)\n",
      "     |      Remove all conditions from this check instance.\n",
      "     |  \n",
      "     |  conditions_decision(self, result: deepchecks.base.check.CheckResult) -> List[deepchecks.base.condition.ConditionResult]\n",
      "     |      Run conditions on given result.\n",
      "     |  \n",
      "     |  params(self) -> Dict\n",
      "     |      Return parameters to show when printing the check.\n",
      "     |  \n",
      "     |  remove_condition(self, index: int)\n",
      "     |      Remove given condition by index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index (int): index of condtion to remove\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from BaseCheck:\n",
      "     |  \n",
      "     |  name() from abc.ABCMeta\n",
      "     |      Name of class in split camel case.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCheck:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SingleDatasetBaseCheck(BaseCheck)\n",
      "     |  Parent class for checks that only use one dataset.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SingleDatasetBaseCheck\n",
      "     |      BaseCheck\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  run(self, dataset, model=None) -> deepchecks.base.check.CheckResult\n",
      "     |      Define run signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'run'})\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCheck:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, tabs=0, prefix='')\n",
      "     |      Representation of check as string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tabs (int): number of tabs to shift by the output\n",
      "     |  \n",
      "     |  add_condition(self, name: str, condition_func: Callable[[Any], Union[deepchecks.base.condition.ConditionResult, bool]], **params)\n",
      "     |      Add new condition function to the check.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          name (str): Name of the condition. should explain the condition action and parameters\n",
      "     |          condition_func (Callable[[Any], Union[List[ConditionResult], bool]]): Function which gets the value of the\n",
      "     |              check and returns object of List[ConditionResult] or boolean.\n",
      "     |          params: Additional parameters to pass when calling the condition function.\n",
      "     |  \n",
      "     |  clean_conditions(self)\n",
      "     |      Remove all conditions from this check instance.\n",
      "     |  \n",
      "     |  conditions_decision(self, result: deepchecks.base.check.CheckResult) -> List[deepchecks.base.condition.ConditionResult]\n",
      "     |      Run conditions on given result.\n",
      "     |  \n",
      "     |  params(self) -> Dict\n",
      "     |      Return parameters to show when printing the check.\n",
      "     |  \n",
      "     |  remove_condition(self, index: int)\n",
      "     |      Remove given condition by index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index (int): index of condtion to remove\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from BaseCheck:\n",
      "     |  \n",
      "     |  name() from abc.ABCMeta\n",
      "     |      Name of class in split camel case.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCheck:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Suite(BaseSuite)\n",
      "     |  Suite(name: str, *checks)\n",
      "     |  \n",
      "     |  Suite to run checks of types: TrainTestBaseCheck, SingleDatasetBaseCheck, ModelOnlyBaseCheck.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Suite\n",
      "     |      BaseSuite\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  run(self, train_dataset: Optional[deepchecks.base.dataset.Dataset] = None, test_dataset: Optional[deepchecks.base.dataset.Dataset] = None, model: object = None) -> deepchecks.base.suite.SuiteResult\n",
      "     |      Run all checks.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        train_dataset: Dataset object, representing data an estimator was fitted on\n",
      "     |        test_dataset: Dataset object, representing data an estimator predicts on\n",
      "     |        model: A scikit-learn-compatible fitted estimator instance\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        List[CheckResult] - All results by all initialized checks\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |           ValueError if check_datasets_policy is not of allowed types\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  supported_checks() -> Tuple from builtins.type\n",
      "     |      Return tuple of supported check types of this suite.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSuite:\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      Access check inside the suite by name.\n",
      "     |  \n",
      "     |  __init__(self, name: str, *checks)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, tabs=0)\n",
      "     |      Representation of suite as string.\n",
      "     |  \n",
      "     |  add(self, check)\n",
      "     |      Add a check or a suite to current suite.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          check (BaseCheck): A check or suite to add.\n",
      "     |  \n",
      "     |  remove(self, index: int)\n",
      "     |      Remove a check by given index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index (int): Index of check to remove.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseSuite:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SuiteResult(builtins.object)\n",
      "     |  SuiteResult(name: str, results)\n",
      "     |  \n",
      "     |  Contain the results of a suite run.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name: str, results)\n",
      "     |      Initialize suite result.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return default __repr__ function uses value.\n",
      "     |  \n",
      "     |  save_as_html(self, file=None)\n",
      "     |      Save output as html file.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |         file (filename or file-like object): The file to write the HTML output to.\n",
      "     |                                              If None writes to output.html\n",
      "     |  \n",
      "     |  show(self)\n",
      "     |      Display suite result.\n",
      "     |  \n",
      "     |  to_json(self, with_display: bool = True)\n",
      "     |      Return check result as json.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          with_display (bool): controls if to serialize display of checks or not\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          {'name': .., 'results': ..}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __annotations__ = {'name': <class 'str'>, 'results': typing.List[typin...\n",
      "    \n",
      "    class TrainTestBaseCheck(BaseCheck)\n",
      "     |  Parent class for checks that compare two datasets.\n",
      "     |  \n",
      "     |  The class checks train dataset and test dataset for model training and test.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TrainTestBaseCheck\n",
      "     |      BaseCheck\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  run(self, train_dataset, test_dataset, model=None) -> deepchecks.base.check.CheckResult\n",
      "     |      Define run signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'run'})\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCheck:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, tabs=0, prefix='')\n",
      "     |      Representation of check as string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tabs (int): number of tabs to shift by the output\n",
      "     |  \n",
      "     |  add_condition(self, name: str, condition_func: Callable[[Any], Union[deepchecks.base.condition.ConditionResult, bool]], **params)\n",
      "     |      Add new condition function to the check.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          name (str): Name of the condition. should explain the condition action and parameters\n",
      "     |          condition_func (Callable[[Any], Union[List[ConditionResult], bool]]): Function which gets the value of the\n",
      "     |              check and returns object of List[ConditionResult] or boolean.\n",
      "     |          params: Additional parameters to pass when calling the condition function.\n",
      "     |  \n",
      "     |  clean_conditions(self)\n",
      "     |      Remove all conditions from this check instance.\n",
      "     |  \n",
      "     |  conditions_decision(self, result: deepchecks.base.check.CheckResult) -> List[deepchecks.base.condition.ConditionResult]\n",
      "     |      Run conditions on given result.\n",
      "     |  \n",
      "     |  params(self) -> Dict\n",
      "     |      Return parameters to show when printing the check.\n",
      "     |  \n",
      "     |  remove_condition(self, index: int)\n",
      "     |      Remove given condition by index.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          index (int): index of condtion to remove\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from BaseCheck:\n",
      "     |  \n",
      "     |  name() from abc.ABCMeta\n",
      "     |      Name of class in split camel case.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCheck:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Dataset', 'BaseCheck', 'SingleDatasetBaseCheck', 'TrainTes...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\msi\\anaconda3\\envs\\mlops\\lib\\site-packages\\deepchecks\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import deepchecks\n",
    "help(deepchecks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepchecks.tabular'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepchecks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msuites\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m full_suite\n\u001b[0;32m      2\u001b[0m suites\u001b[38;5;241m=\u001b[39mfull_suite()\n\u001b[0;32m      3\u001b[0m suites\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'deepchecks.tabular'"
     ]
    }
   ],
   "source": [
    "from deepchecks.tabular.suites import full_suite\n",
    "suites=full_suite()\n",
    "suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trans_date_trans_time',\n",
       " 'merchant',\n",
       " 'category',\n",
       " 'first',\n",
       " 'last',\n",
       " 'gender',\n",
       " 'street',\n",
       " 'city',\n",
       " 'state',\n",
       " 'job',\n",
       " 'dob',\n",
       " 'trans_num']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features= df.select_dtypes(include=['object']).columns.tolist()\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4><b>Dataset Description</b></h4><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"min-width: 15px;\"></th>\n",
       "      <th style=\"min-width: 15px;\">Column</th>\n",
       "      <th style=\"min-width: 15px;\">DType</th>\n",
       "      <th style=\"min-width: 15px;\">Kind</th>\n",
       "      <th style=\"min-width: 15px;\">Additional Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_fraud</td>\n",
       "      <td>integer</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trans_date_trans_time</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cc_num</td>\n",
       "      <td>integer</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>merchant</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amt</td>\n",
       "      <td>floating</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>first</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>last</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gender</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>street</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>city</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>state</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zip</td>\n",
       "      <td>integer</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lat</td>\n",
       "      <td>floating</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>long</td>\n",
       "      <td>floating</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>city_pop</td>\n",
       "      <td>integer</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>job</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dob</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>trans_num</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>unix_time</td>\n",
       "      <td>integer</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>merch_lat</td>\n",
       "      <td>floating</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>merch_long</td>\n",
       "      <td>floating</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><h4><b>Dataset Content</b></h4><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"min-width: 15px;\"></th>\n",
       "      <th style=\"min-width: 15px;\">is_fraud</th>\n",
       "      <th style=\"min-width: 15px;\">trans_date_trans_time</th>\n",
       "      <th style=\"min-width: 15px;\">cc_num</th>\n",
       "      <th style=\"min-width: 15px;\">merchant</th>\n",
       "      <th>...</th>\n",
       "      <th style=\"min-width: 15px;\">trans_num</th>\n",
       "      <th style=\"min-width: 15px;\">unix_time</th>\n",
       "      <th style=\"min-width: 15px;\">merch_lat</th>\n",
       "      <th style=\"min-width: 15px;\">merch_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>...</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>...</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>...</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>...</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>...</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 15:36:49</td>\n",
       "      <td>2475085306462014</td>\n",
       "      <td>fraud_O'Reilly, Mohr and Purdy</td>\n",
       "      <td>...</td>\n",
       "      <td>085e8f89f41378f4bd21ed8a59065fee</td>\n",
       "      <td>1330443409</td>\n",
       "      <td>44.718105</td>\n",
       "      <td>-95.843397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 15:37:27</td>\n",
       "      <td>4005676619255478</td>\n",
       "      <td>fraud_Kub PLC</td>\n",
       "      <td>...</td>\n",
       "      <td>9988dd4de1bb2182a7b3ec5f1ede1e34</td>\n",
       "      <td>1330443447</td>\n",
       "      <td>29.931844</td>\n",
       "      <td>-90.610715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 15:37:34</td>\n",
       "      <td>3519232971341141</td>\n",
       "      <td>fraud_Schuppe-Schuppe</td>\n",
       "      <td>...</td>\n",
       "      <td>70151fb544afe365dc163889d67f5be6</td>\n",
       "      <td>1330443454</td>\n",
       "      <td>41.076153</td>\n",
       "      <td>-80.506107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 15:38:11</td>\n",
       "      <td>4040099974063068803</td>\n",
       "      <td>fraud_Rippin-VonRueden</td>\n",
       "      <td>...</td>\n",
       "      <td>bc2adb0fad8f733cdc21ebefcc79ddf3</td>\n",
       "      <td>1330443491</td>\n",
       "      <td>48.535070</td>\n",
       "      <td>-102.524262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 15:40:20</td>\n",
       "      <td>6595970453799027</td>\n",
       "      <td>fraud_Kessler Group</td>\n",
       "      <td>...</td>\n",
       "      <td>fd4a6a1b893c2045d7310c70c1d9ea1f</td>\n",
       "      <td>1330443620</td>\n",
       "      <td>39.718206</td>\n",
       "      <td>-73.627417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepchecks.tabular import Dataset\n",
    "dataframeTest=Dataset(df=df,label='is_fraud',cat_features=cat_features)\n",
    "dataframeTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923b4de9f8bc482ca090241f858bd5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_ZUZJG1RME0GX1CNATP9GZESCK\">Full Suite</h1>\\n<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suites.run(dataframeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4><b>Dataset Description</b></h4><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"min-width: 15px;\"></th>\n",
       "      <th style=\"min-width: 15px;\">Column</th>\n",
       "      <th style=\"min-width: 15px;\">DType</th>\n",
       "      <th style=\"min-width: 15px;\">Kind</th>\n",
       "      <th style=\"min-width: 15px;\">Additional Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_fraud</td>\n",
       "      <td>integer</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trans_date_trans_time</td>\n",
       "      <td>string</td>\n",
       "      <td>Other Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cc_num</td>\n",
       "      <td>integer</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>merchant</td>\n",
       "      <td>string</td>\n",
       "      <td>Other Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amt</td>\n",
       "      <td>floating</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>first</td>\n",
       "      <td>string</td>\n",
       "      <td>Other Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>last</td>\n",
       "      <td>string</td>\n",
       "      <td>Other Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gender</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>street</td>\n",
       "      <td>string</td>\n",
       "      <td>Other Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>city</td>\n",
       "      <td>string</td>\n",
       "      <td>Other Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>state</td>\n",
       "      <td>string</td>\n",
       "      <td>Other Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zip</td>\n",
       "      <td>integer</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lat</td>\n",
       "      <td>floating</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>long</td>\n",
       "      <td>floating</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>city_pop</td>\n",
       "      <td>integer</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>job</td>\n",
       "      <td>string</td>\n",
       "      <td>Categorical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dob</td>\n",
       "      <td>string</td>\n",
       "      <td>Other Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>trans_num</td>\n",
       "      <td>string</td>\n",
       "      <td>Other Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>unix_time</td>\n",
       "      <td>integer</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>merch_lat</td>\n",
       "      <td>floating</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>merch_long</td>\n",
       "      <td>floating</td>\n",
       "      <td>Numerical Feature</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><h4><b>Dataset Content</b></h4><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"min-width: 15px;\"></th>\n",
       "      <th style=\"min-width: 15px;\">is_fraud</th>\n",
       "      <th style=\"min-width: 15px;\">trans_date_trans_time</th>\n",
       "      <th style=\"min-width: 15px;\">cc_num</th>\n",
       "      <th style=\"min-width: 15px;\">merchant</th>\n",
       "      <th>...</th>\n",
       "      <th style=\"min-width: 15px;\">trans_num</th>\n",
       "      <th style=\"min-width: 15px;\">unix_time</th>\n",
       "      <th style=\"min-width: 15px;\">merch_lat</th>\n",
       "      <th style=\"min-width: 15px;\">merch_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>...</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>...</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>...</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>...</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>...</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 15:36:49</td>\n",
       "      <td>2475085306462014</td>\n",
       "      <td>fraud_O'Reilly, Mohr and Purdy</td>\n",
       "      <td>...</td>\n",
       "      <td>085e8f89f41378f4bd21ed8a59065fee</td>\n",
       "      <td>1330443409</td>\n",
       "      <td>44.718105</td>\n",
       "      <td>-95.843397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 15:37:27</td>\n",
       "      <td>4005676619255478</td>\n",
       "      <td>fraud_Kub PLC</td>\n",
       "      <td>...</td>\n",
       "      <td>9988dd4de1bb2182a7b3ec5f1ede1e34</td>\n",
       "      <td>1330443447</td>\n",
       "      <td>29.931844</td>\n",
       "      <td>-90.610715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 15:37:34</td>\n",
       "      <td>3519232971341141</td>\n",
       "      <td>fraud_Schuppe-Schuppe</td>\n",
       "      <td>...</td>\n",
       "      <td>70151fb544afe365dc163889d67f5be6</td>\n",
       "      <td>1330443454</td>\n",
       "      <td>41.076153</td>\n",
       "      <td>-80.506107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 15:38:11</td>\n",
       "      <td>4040099974063068803</td>\n",
       "      <td>fraud_Rippin-VonRueden</td>\n",
       "      <td>...</td>\n",
       "      <td>bc2adb0fad8f733cdc21ebefcc79ddf3</td>\n",
       "      <td>1330443491</td>\n",
       "      <td>48.535070</td>\n",
       "      <td>-102.524262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-28 15:40:20</td>\n",
       "      <td>6595970453799027</td>\n",
       "      <td>fraud_Kessler Group</td>\n",
       "      <td>...</td>\n",
       "      <td>fd4a6a1b893c2045d7310c70c1d9ea1f</td>\n",
       "      <td>1330443620</td>\n",
       "      <td>39.718206</td>\n",
       "      <td>-73.627417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfcopy=df.copy()\n",
    "dfcopy.drop(['trans_date_trans_time','first', 'last', 'dob','trans_num','cc_num','unix_time','merchant', 'street', 'city','lat','long','state'] , axis=1, inplace=True)\n",
    "#get categorical features\n",
    "cat_features= dfcopy.select_dtypes(include=['object']).columns.tolist()\n",
    "dataframeTest=Dataset(df=df,label='is_fraud',cat_features=cat_features)\n",
    "dataframeTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9783986f8cf94699846589e8757f66c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_9SLX2UGCYGZ0MBNJM8YLEO7TW\">Full Suite</h1>\\n<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suites.run(dataframeTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Individual Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bassembenhamed/opt/anaconda3/envs/bootcamp/lib/python3.10/site-packages/deepchecks/suites.py:21: DeprecationWarning:\n",
      "\n",
      "Ability to import tabular suites from the `deepchecks.suites` is deprecated, please import from `deepchecks.tabular.suites` instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepchecks.suites import data_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Integrity Suite: [\n",
       "\t0: IsSingleValue\n",
       "\t\tConditions:\n",
       "\t\t\t0: Does not contain only a single value\n",
       "\t1: SpecialCharacters\n",
       "\t\tConditions:\n",
       "\t\t\t0: Ratio of samples containing solely special character is less or equal to 0.1%\n",
       "\t2: MixedNulls\n",
       "\t\tConditions:\n",
       "\t\t\t0: Number of different null types is less or equal to 1\n",
       "\t3: MixedDataTypes\n",
       "\t\tConditions:\n",
       "\t\t\t0: Rare data types in column are either more than 10% or less than 1% of the data\n",
       "\t4: StringMismatch\n",
       "\t\tConditions:\n",
       "\t\t\t0: No string variants\n",
       "\t5: DataDuplicates\n",
       "\t\tConditions:\n",
       "\t\t\t0: Duplicate data ratio is less or equal to 0%\n",
       "\t6: StringLengthOutOfBounds\n",
       "\t\tConditions:\n",
       "\t\t\t0: Ratio of string length outliers is less or equal to 0%\n",
       "\t7: ConflictingLabels\n",
       "\t\tConditions:\n",
       "\t\t\t0: Ambiguous sample ratio is less or equal to 0%\n",
       "\t8: OutlierSampleDetection\n",
       "\t9: FeatureLabelCorrelation(ppscore_params={}, random_state=42)\n",
       "\t\tConditions:\n",
       "\t\t\t0: Features' Predictive Power Score is less than 0.8\n",
       "\t10: FeatureFeatureCorrelation\n",
       "\t\tConditions:\n",
       "\t\t\t0: Not more than 0 pairs are correlated above 0.9\n",
       "\t11: IdentifierLabelCorrelation(ppscore_params={})\n",
       "\t\tConditions:\n",
       "\t\t\t0: Identifier columns PPS is less or equal to 0\n",
       "]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrity_test=data_integrity()\n",
    "integrity_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51403115548d4fff86d56789bb6b46b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_0FUUR9OTGPO7E7VGL3D7SK4GD\">Data Integrity Sui…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_integrity_test=integrity_test.run(dataframeTest)\n",
    "result_integrity_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Saving result as html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "htmlSave=result_integrity_test.save_as_html('result_integrity_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Distribution tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train,df_test=train_test_split(dfcopy,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train:(80000, 9)\n",
      "df_test:(20000, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f\"df_train:{df_train.shape}\")\n",
    "print(f\"df_test:{df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c8811f285542c79975eabeb78272ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_9CKN8A40NBEVA014Y274COKB0\">Full Suite</h1>\\n<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#transformation\n",
    "ds_train=Dataset(df=df_train,label='is_fraud',cat_features=cat_features)\n",
    "ds_test=Dataset(df=df_test,label='is_fraud',cat_features=cat_features)\n",
    "data_distribution_test=suites.run(train_dataset=ds_train,test_dataset=ds_test)\n",
    "data_distribution_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataIntegrityHtmlSaved=data_distribution_test.save_as_html('data_distribution_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model analysis and validation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "dfModel=df.copy()\n",
    "dfModel.drop(['trans_date_trans_time','first', 'last', 'dob','trans_num','cc_num','unix_time','merchant', 'street', 'city','lat','long','state','job'] , axis=1, inplace=True)\n",
    "dfModelCopy=dfModel.copy()\n",
    "#get categorical features\n",
    "cat_features= dfModel.select_dtypes(include=['object']).columns.tolist()\n",
    "num_features= dfModel.select_dtypes(include=['integer']).columns.tolist()\n",
    "num_features.remove(\"is_fraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>zip</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>category_entertainment</th>\n",
       "      <th>category_food_dining</th>\n",
       "      <th>category_gas_transport</th>\n",
       "      <th>category_grocery_net</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>category_kids_pets</th>\n",
       "      <th>category_misc_net</th>\n",
       "      <th>category_misc_pos</th>\n",
       "      <th>category_personal_care</th>\n",
       "      <th>category_shopping_net</th>\n",
       "      <th>category_shopping_pos</th>\n",
       "      <th>category_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.97</td>\n",
       "      <td>0</td>\n",
       "      <td>28654</td>\n",
       "      <td>3495</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.23</td>\n",
       "      <td>0</td>\n",
       "      <td>99160</td>\n",
       "      <td>149</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220.11</td>\n",
       "      <td>1</td>\n",
       "      <td>83252</td>\n",
       "      <td>4154</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.00</td>\n",
       "      <td>1</td>\n",
       "      <td>59632</td>\n",
       "      <td>1939</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.96</td>\n",
       "      <td>1</td>\n",
       "      <td>24433</td>\n",
       "      <td>99</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      amt  gender    zip  city_pop  merch_lat  merch_long  is_fraud  \\\n",
       "0    4.97       0  28654      3495  36.011293  -82.048315         0   \n",
       "1  107.23       0  99160       149  49.159047 -118.186462         0   \n",
       "2  220.11       1  83252      4154  43.150704 -112.154481         0   \n",
       "3   45.00       1  59632      1939  47.034331 -112.561071         0   \n",
       "4   41.96       1  24433        99  38.674999  -78.632459         0   \n",
       "\n",
       "   category_entertainment  category_food_dining  category_gas_transport  \\\n",
       "0                       0                     0                       0   \n",
       "1                       0                     0                       0   \n",
       "2                       1                     0                       0   \n",
       "3                       0                     0                       1   \n",
       "4                       0                     0                       0   \n",
       "\n",
       "   category_grocery_net  category_grocery_pos  category_health_fitness  \\\n",
       "0                     0                     0                        0   \n",
       "1                     0                     1                        0   \n",
       "2                     0                     0                        0   \n",
       "3                     0                     0                        0   \n",
       "4                     0                     0                        0   \n",
       "\n",
       "   category_home  category_kids_pets  category_misc_net  category_misc_pos  \\\n",
       "0              0                   0                  1                  0   \n",
       "1              0                   0                  0                  0   \n",
       "2              0                   0                  0                  0   \n",
       "3              0                   0                  0                  0   \n",
       "4              0                   0                  0                  1   \n",
       "\n",
       "   category_personal_care  category_shopping_net  category_shopping_pos  \\\n",
       "0                       0                      0                      0   \n",
       "1                       0                      0                      0   \n",
       "2                       0                      0                      0   \n",
       "3                       0                      0                      0   \n",
       "4                       0                      0                      0   \n",
       "\n",
       "   category_travel  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only for gender\n",
    "encode_dict = {  # Encoding dictionary\n",
    "    'F': 0, 'M': 1}\n",
    "dfModel['gender'] = dfModel['gender'].map(encode_dict)\n",
    "dummy_cols = ['category']\n",
    "#For other categorical columns\n",
    "dfModel = pd.get_dummies(dfModel, columns=dummy_cols)\n",
    "dfModel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = dfModel.drop('is_fraud', axis=1)  # Select features\n",
    "y = dfModel['is_fraud']  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)  # Split data 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize train & test features\n",
    "scaler = MinMaxScaler()\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "method= SMOTE()\n",
    "x_resampled, y_resampled = method.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model=LogisticRegression(solver='lbfgs' ,max_iter=10000)\n",
    "model.fit(x_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deepchecks - WARNING - It is recommended to initialize Dataset with categorical features by doing \"Dataset(df, cat_features=categorical_list)\". No categorical features were passed, therefore heuristically inferring categorical features in the data. 15 categorical features were inferred.: gender, category_entertainment, category_food_dining, category_gas_transport, category_grocery_net, category_grocery_pos, category_health_fitness... For full list use dataset.cat_features\n",
      "deepchecks - WARNING - It is recommended to initialize Dataset with categorical features by doing \"Dataset(df, cat_features=categorical_list)\". No categorical features were passed, therefore heuristically inferring categorical features in the data. 15 categorical features were inferred.: gender, category_entertainment, category_food_dining, category_gas_transport, category_grocery_net, category_grocery_pos, category_health_fitness... For full list use dataset.cat_features\n"
     ]
    }
   ],
   "source": [
    "df_train,df_test=train_test_split(dfModel,test_size=0.2)\n",
    "df_train_model=Dataset(df=df_train,label='is_fraud')\n",
    "df_test_model=Dataset(df=df_test,label='is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_model_test=suites.run(train_dataset=df_train_model,test_dataset=df_test_model,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f942786ab14752a50313258b86b852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HTML(value='\\n<h1 id=\"summary_K5OXID678XGEQ3J0POMUTO8RQ\">Full Suite</h1>\\n<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "html_result_model_test=result_model_test.save_as_html('result_model_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f47cee5ce7f0e86d1697bc830ef64d3cfed3ed1d870feb222f972fa9d7058365"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
